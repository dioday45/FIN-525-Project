{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f487bfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import numpy as np\n",
    "from numpy import linalg as LA\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import networkx as nx\n",
    "import community\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69c3831",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline = \"baseline_720_24_1dot02.pkl\" \n",
    "thresh = \"thresh_720_24_0dot3_1.pkl\"\n",
    "thresh2 = \"threshold2_720_24_1dot05_3.pkl\"\n",
    "\n",
    "with open(\"../data/processed/\"+baseline, 'rb') as f:\n",
    "    baseline_clusters = pickle.load(f)\n",
    "    \n",
    "with open(\"../data/processed/\"+thresh, 'rb') as f:\n",
    "    thresh_clusters = pickle.load(f)\n",
    "\n",
    "with open(\"../data/processed/\"+thresh2, 'rb') as f:\n",
    "    thresh2_clusters = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b95b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_list = [\"baseline_clusters\", \"thresh2_clusters\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b609432f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_clustering = {\"baseline_clusters\":baseline_clusters, \"thresh2_clusters\": thresh2_clusters}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b82b813",
   "metadata": {},
   "source": [
    "## Stability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31174eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rand_score(clusters):\n",
    "    nb_clusters = len(clusters.keys())\n",
    "    rand_score = []\n",
    "    for i in range(nb_clusters - 1):\n",
    "        score = adjusted_rand_score(list(clusters[list(clusters.keys())[i]].values()), list(clusters[list(clusters.keys())[i+1]].values()))\n",
    "        rand_score.append(score)\n",
    "    return rand_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefd6062",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_nb_clusters(clusters):\n",
    "    nb_clusters = len(clusters.keys())\n",
    "    list_nb_clusters = []\n",
    "    for i in range(nb_clusters - 1):\n",
    "        nb = max(clusters[list(clusters.keys())[i]].values())\n",
    "        list_nb_clusters.append(nb)\n",
    "    return list_nb_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7e0471",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_sizes = {}\n",
    "for i in range(len(clustering_list)):\n",
    "    clustering_sizes[clustering_list[i]] = compute_nb_clusters(all_clustering[clustering_list[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e556e7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data in a single dataframe\n",
    "df_plot = pd.DataFrame({'Group': [c for c in clustering_list for size in clustering_sizes[c]],\n",
    "                   'Value': [size for c in clustering_list for size in clustering_sizes[c]]})\n",
    "\n",
    "# Create a boxplot with Seaborn\n",
    "sns.boxplot(x='Group', y='Value', data=df_plot)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Distribution of the number of clusters')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec55d0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_stability = {}\n",
    "for i in range(len(clustering_list)):\n",
    "    clustering_stability[clustering_list[i]] = compute_rand_score(all_clustering[clustering_list[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f256bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data in a single dataframe\n",
    "df_plot = pd.DataFrame({'Group': [c for c in clustering_list for s in clustering_stability[c]],\n",
    "                   'Value': [s for c in clustering_list for s in clustering_stability[c]]})\n",
    "\n",
    "# Create a boxplot with Seaborn\n",
    "sns.boxplot(x='Group', y='Value', data=df_plot)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Distribution of the number of clusters')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea280e5",
   "metadata": {},
   "source": [
    "## Markowitz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501fdc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_representatives(clusters):\n",
    "    nb_clustering = len(clusters.keys())\n",
    "    representatives = []\n",
    "    for i in range(nb_clustering):\n",
    "        \n",
    "        current_representatives = []\n",
    "        current_cluster = clusters[list(clusters.keys())[i]]\n",
    "\n",
    "        # Loop through each community\n",
    "        for group in range(max(current_cluster.values())):\n",
    "            subset = [cluster[0] for cluster in current_cluster.items() if cluster[1] == group]\n",
    "            # Subset the data for the current group\n",
    "            subset_data = df[subset]\n",
    "\n",
    "            # Apply PCA\n",
    "            pca = PCA()\n",
    "            principal_components = pca.fit_transform(subset_data)\n",
    "\n",
    "            # Identify the leading coin (biggest contributor in the first principal component)\n",
    "            leading_coin_index = np.argmax(np.abs(pca.components_[0]))\n",
    "            leading_coin = subset_data.columns[leading_coin_index]\n",
    "            current_representatives.append(leading_coin)\n",
    "            # Print\n",
    "        representatives.append(current_representatives)\n",
    "    return representatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea096cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def out_sample_risks(clusters, representatives):\n",
    "\n",
    "    nb_clustering = len(clusters.keys())\n",
    "    out_vol = []\n",
    "    vol_abs = []\n",
    "    for i in range(nb_clustering):\n",
    "        length_window = list(clusters.keys())[i][1] - list(clusters.keys())[i][0]\n",
    "\n",
    "        corr_mat_insample = df.loc[list(clusters.keys())[i][0]:list(clusters.keys())[i][1], representatives[i]].corr()\n",
    "        corr_mat_outsample = df.loc[list(clusters.keys())[i][1]:list(clusters.keys())[i][1] + length_window, representatives[i]].corr()\n",
    "\n",
    "        inv_corr_insample = LA.inv(corr_mat_insample.to_numpy())\n",
    "        w_opt = inv_corr_insample @ np.ones(len(inv_corr_insample)) / (np.ones(len(inv_corr_insample)) @ inv_corr_insample @ np.ones(len(inv_corr_insample)))\n",
    "\n",
    "        realized_vol = w_opt @ corr_mat_insample @ w_opt.T\n",
    "        out_sample_vol = w_opt @ corr_mat_outsample @ w_opt.T\n",
    "        out_vol.append(out_sample_vol)\n",
    "        vol_abs.append(abs(realized_vol-out_sample_vol)/realized_vol)\n",
    "    return (out_vol, vol_abs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc56b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed/normalized_log_ret.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1381d7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "clustering_out_vol = {}\n",
    "for i in range(len(clustering_list)):\n",
    "    representatives = find_representatives(all_clustering[clustering_list[i]])\n",
    "    clustering_out_vol[clustering_list[i]] = out_sample_risks(all_clustering[clustering_list[i]], representatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a1bac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data in a single dataframe\n",
    "df_plot = pd.DataFrame({'Group': [c for c in clustering_list for risk in clustering_out_vol[c][0]],\n",
    "                   'Value': [s for c in clustering_list for s in clustering_out_vol[c][0]]})\n",
    "\n",
    "# Create a boxplot with Seaborn\n",
    "sns.boxplot(x='Group', y='Value', data=df_plot)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Out-of-sample volatility')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f7077a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the data in a single dataframe\n",
    "df_plot = pd.DataFrame({'Group': [c for c in clustering_list for risk in clustering_out_vol[c][1]],\n",
    "                   'Value': [s for c in clustering_list for s in clustering_out_vol[c][1]]})\n",
    "\n",
    "# Create a boxplot with Seaborn\n",
    "sns.boxplot(x='Group', y='Value', data=df_plot)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Group')\n",
    "plt.ylabel('Value')\n",
    "plt.title('Absolute difference volatility')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
