{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89df1666",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T20:55:00.737020Z",
     "start_time": "2023-12-30T20:55:00.695877Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg as LA\n",
    "import networkx as nx\n",
    "import community\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ebc8b9d04dc43c",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Data preparation\n",
    "### Loading of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc598690abe1b7e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T20:55:02.070064Z",
     "start_time": "2023-12-30T20:55:02.030200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Download names to make it more friendly\n",
    "json_file_path_1 = '../data/all_coins_by_mc_1.json'\n",
    "json_file_path_2 = '../data/all_coins_by_mc_2.json'\n",
    "\n",
    "# Open the JSON file and load its contents\n",
    "with open(json_file_path_1, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "with open(json_file_path_2, 'r') as file:\n",
    "    data = data + json.load(file)\n",
    "# Now, 'data' contains the contents of the JSON file as a Python object (dictionary, list, etc.)\n",
    "names_list = [stock[\"name\"] for stock in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7b3ac4",
   "metadata": {},
   "source": [
    "### Load price data and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab398b5bbcc7498f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T20:55:09.738571Z",
     "start_time": "2023-12-30T20:55:06.968350Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/processed/prices.csv\", parse_dates=['date'])\n",
    "data.rename(columns={data.columns[0]: 'date'}, inplace=True)\n",
    "data.set_index(\"date\", inplace=True)\n",
    "data.columns = names_list\n",
    "data = data.loc['2021-01-01':'2022-12-31'] # Filter\n",
    "data = data.dropna(axis=1, how='all') # Drop all columns that contains only null value\n",
    "data = data.dropna(axis=1, thresh=0.95*len(data.index)) # Drop columns that contains more than 25% of null value\n",
    "data = data.ffill() # ffill null values\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f712dd",
   "metadata": {},
   "source": [
    "### Compute and normalize Hourly log-return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50a6d984",
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_returns_pct = data.pct_change()\n",
    "hourly_returns_pct = hourly_returns_pct.iloc[1:]\n",
    "hourly_returns_pct.to_csv(\"../data/processed/hourly_return.csv\")\n",
    "hourly_log_returns = np.log(hourly_returns_pct + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96a0282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "hourly_log_returns = pd.DataFrame(scaler.fit_transform(hourly_log_returns), columns=hourly_log_returns.columns, index=hourly_log_returns.index)\n",
    "hourly_log_returns.to_csv(\"../data/processed/normalized_log_ret.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac8af05",
   "metadata": {},
   "source": [
    "## Network creation methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f72c4a4b",
   "metadata": {},
   "source": [
    "### Eigenvvalues clipping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "84a93eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_C_minus_C0(lambdas, v, lambda_plus, removeMarketMode=False):\n",
    "    N=len(lambdas)\n",
    "    C_clean=np.zeros((N, N))\n",
    "\n",
    "    order = np.argsort(lambdas)\n",
    "    lambdas,v = lambdas[order],v[:,order]\n",
    "\n",
    "    v_m=np.matrix(v)\n",
    "\n",
    "    # note that the eivenvalues are sorted\n",
    "    for i in range(1*removeMarketMode,N):\n",
    "        if lambdas[i]>lambda_plus:\n",
    "            C_clean=C_clean+lambdas[i] * np.dot(v_m[:,i],v_m[:,i].T)\n",
    "    return C_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3354d5a",
   "metadata": {},
   "source": [
    "### From C (as in class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26402954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_network(R, mst=False):   # R is a matrix of return\n",
    "    N=R.shape[1]\n",
    "    T=R.shape[0]\n",
    "\n",
    "    q=N*1./T\n",
    "    lambda_plus=(1.+np.sqrt(q))**2\n",
    "    C=R.corr()\n",
    "    lambdas, v = LA.eigh(C)\n",
    "    C_s=compute_C_minus_C0(lambdas,v,lambda_plus)\n",
    "    C_s = np.abs(C_s)\n",
    "\n",
    "    return nx.from_numpy_array(C_s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1ad14e",
   "metadata": {},
   "source": [
    "### Minimum Spanning Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6bcf1ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mst_network(R):\n",
    "    N=R.shape[1]\n",
    "    T=R.shape[0]\n",
    "\n",
    "    q=N*1./T\n",
    "    lambda_plus=(1.+np.sqrt(q))**2\n",
    "    C=R.corr()\n",
    "    lambdas, v = LA.eigh(C)\n",
    "    C_s=compute_C_minus_C0(lambdas,v,lambda_plus)\n",
    "    \n",
    "    # Compute distance matrix\n",
    "    D = np.sqrt(2*(1-C_s))\n",
    "    # Compute MST\n",
    "    G = nx.from_numpy_array(D)\n",
    "    return nx.minimum_spanning_tree(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4b5f2b",
   "metadata": {},
   "source": [
    "### Threshold network\n",
    "- Compute C and D\n",
    "- Create G from D\n",
    "- Remove all edge with weight smaller than *threshold*\n",
    "- Louvain clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ff69ddd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_network(R, threshold=1.41):\n",
    "    N = R.shape[1]\n",
    "    T = R.shape[0]\n",
    "    \n",
    "    # Compute lambda_plus and correlation matrix\n",
    "    q = N * 1. / T\n",
    "    lambda_plus = (1. + np.sqrt(q)) ** 2\n",
    "    C = R.corr()\n",
    "    lambdas, v = LA.eigh(C)\n",
    "    C = compute_C_minus_C0(lambdas, v, lambda_plus)\n",
    "\n",
    "    # Compute distance matrix\n",
    "    D = np.sqrt(2*(1-C))    \n",
    "    \n",
    "    # Compute graph\n",
    "    G = nx.from_numpy_array(D)\n",
    "    edges_to_remove = [edge for edge, attr in G.edges.items() if attr['weight'] >= threshold]\n",
    "    G.remove_edges_from(edges_to_remove)\n",
    "    return G"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a582a4a8",
   "metadata": {},
   "source": [
    "### Planar Maximally Filtered Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7c29435d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_graph_edges(G):\n",
    "    sorted_edges = []\n",
    "    for source, dest, data in sorted(G.edges(data=True), key=lambda x: x[2]['weight']):\n",
    "        sorted_edges.append({'source': source,\n",
    "                             'dest': dest,\n",
    "                             'weight': data['weight']})\n",
    "        \n",
    "    return sorted_edges\n",
    "\n",
    "def compute_PMFG(sorted_edges, nb_nodes):\n",
    "    PMFG = nx.Graph()\n",
    "    for edge in sorted_edges:\n",
    "        PMFG.add_edge(edge['source'], edge['dest'])\n",
    "        if not nx.is_planar(PMFG):\n",
    "            PMFG.remove_edge(edge['source'], edge['dest'])\n",
    "            \n",
    "        if len(PMFG.edges()) == 3*(nb_nodes-2):\n",
    "            print('test')\n",
    "            break\n",
    "    \n",
    "    return PMFG\n",
    "\n",
    "\n",
    "def pmfg_network(R):\n",
    "    N = R.shape[1]\n",
    "    T = R.shape[0]\n",
    "    \n",
    "    # Compute lambda_plus and correlation matrix\n",
    "    q = N * 1. / T\n",
    "    lambda_plus = (1. + np.sqrt(q)) ** 2\n",
    "    C = R.corr()\n",
    "    lambdas, v = LA.eigh(C)\n",
    "    C = compute_C_minus_C0(lambdas, v, lambda_plus)\n",
    "\n",
    "    # Compute distance matrix\n",
    "    D = np.sqrt(2*(1-C))    \n",
    "    \n",
    "    # Compute graph\n",
    "    G = nx.from_numpy_array(D)\n",
    "    \n",
    "    sorted_edges = sort_graph_edges(G)\n",
    "    \n",
    "    return compute_PMFG(sorted_edges, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b874c83",
   "metadata": {},
   "source": [
    "## Louvain clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b74a7ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def louvain_clustering(G):\n",
    "    return  community.community_louvain.best_partition(G, resolution=1.05, random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b981a53",
   "metadata": {},
   "source": [
    "## Rolling window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9423506849cb26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-12-30T20:55:17.628520Z",
     "start_time": "2023-12-30T20:55:17.602114Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../data/processed/normalized_log_ret.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "354b83d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_asset(R, partition):\n",
    "    dict_cluster = {}\n",
    "    all_names = list(R.columns)\n",
    "    for i, name in enumerate(all_names):\n",
    "        dict_cluster[name]=partition[i]\n",
    "        \n",
    "    return dict_cluster\n",
    "\n",
    "def clustering(R: pd.DataFrame, period: int=720, interval: int = 24, method:str='baseline') -> dict:\n",
    "    \"\"\"Compute the clusters in a rolling window manner for the return matrix R.\n",
    "\n",
    "    Args:\n",
    "        R (pd.Dataframe): Normalized log-return matrix\n",
    "        period (int, optional): time period_. Defaults to 30 days (720 hours).\n",
    "        interval (int, optional): time interval. Defaults to 1 day (24 hours).\n",
    "        method (str, optional): Clustering method. Defaults to 'baseline'. Can be 'baseline', 'mst' 'threshold', 'pmf'.\n",
    "    \"\"\"\n",
    "    cluster_dict = {}\n",
    "    for t0 in tqdm(range(0, len(R.index)-period, interval)):\n",
    "        R_tmp = R.iloc[t0:t0+period]\n",
    "        if method == 'baseline':\n",
    "            G = baseline_network(R_tmp)\n",
    "        elif method == 'mst':\n",
    "            G = mst_network(R_tmp)\n",
    "        elif method == 'threshold':\n",
    "            G = threshold_network(R_tmp)\n",
    "        elif method == 'pmf':\n",
    "            G = pmfg_network(R_tmp)\n",
    "        else:\n",
    "            raise ValueError(\"Method not recognized\")\n",
    "            \n",
    "        \n",
    "        cluster_dict[(t0, t0+period)] = rename_asset(R_tmp, louvain_clustering(G))\n",
    "            \n",
    "    return cluster_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
